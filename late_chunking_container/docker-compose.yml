networks:
  OCR_Entity_Graph:
    external: true
services:
  semantic_chunker:
    build: 
      context: .
      args:
        HUGGINGFACE_CACHE: ${HUGGINGFACE_CACHE}
    networks:
      - OCR_Entity_Graph
    runtime: nvidia
    deploy:
      #replicas: 3  # to run several worker containers, only works with docker swarm init
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
        NVIDIA_VISIBLE_DEVICES: "all"
        # Chunking config
        CHUNK_TOKEN_LIMIT: "256"
        SIMILARITY_THRESHOLD: "0.89"
        # Model config
        HUGGINGFACE_CACHE: "${HUGGINGFACE_CACHE}"
        MODEL_NAME: "jinaai/jina-embeddings-v3"
        TOKEN_LIMIT: "8192"
        # GraphDB auth
        GRAPHDB_USER: ""
        GRAPHDB_PASSWORD: ""
        # GraphDB connect
        ENDPOINT_URL: "http://host.docker.internal:7200/repositories/AIS/statements"
        GRAPH: "https://lindas.admin.ch/sfa/ais/late-chunks"
        # Weaviate collections
        CHUNK_COLLECTION: "LateChunks"
        DOC_COLLECTION: "LateDocuments"
        # Weaviate connect
        WEAVIATE_HTTP_HOST: "host.docker.internal"
        WEAVIATE_HTTP_PORT: "8080"
        WEAVIATE_HTTP_SECURE: "false"
        WEAVIATE_GRPC_HOST: "host.docker.internal"
        WEAVIATE_GRPC_PORT: "50051"
        WEAVIATE_GRPC_SECURE: "false"
        # Weaviate auth
        WEAVIATE_API_KEY: ""
        WEAVIATE_USER: ""
        WEAVIATE_PASSWORD: ""
        WEAVIATE_BEARER_TOKEN: ""
    volumes:
      - ${HUGGINGFACE_CACHE}:/root/.cache/huggingface
      - ./logs:/logs
    ports:
      - "6000:6000"
      